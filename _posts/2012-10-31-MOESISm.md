---
layout: post
title: The MOESISm (MOESIF) cache coherence protocol
date: 2012-10-31
categories: [Parallel Computing]
---

In one of the courses I took this semester, we were asked to modify an existing invalidation based cache coherence protocol to reduce the off-chip Bandwidth usage. The motivation for this problem statement was limited off-chip bandwidth due to constrained number of pins that a chip can have.

Initially I had used the given benchmarks to determine off-chip bandwidth usage for MSI, MESI and MOESI protocols and among them, MESI seemed to perform the best. The MOESI protocol, in spite of having fewer writebacks (because it allows dirty sharing) lost out on cache-to-cache transfers because the shared state is not allowed to Flush. Hence, although MOESI accounts for Flush in a read after write operation ( â€˜Mâ€™ to â€˜Oâ€™ state transition and â€˜Oâ€™ can Flush), a read after read will cause a block to be brought in from memory (on a miss) even if the cache on same level has a copy. In order to accommodate this request I decided to introduce a new state namely â€˜Smâ€™ (shared master, which I later found to be similar to the Forward state in Intel MESIF protocol) and the results were quite interesting. Below is the explanation for the MOESISm protocol: (the terminology is based on what had been taught in class)

Processor requests to the cache:
- PrRd: Processor request to read to a cache block
- PrWr: Processor request to write to a cache block

Bus-side requests:
- BusRd: Snooped request that some other processor has requested to read a cache block
- BusRdX: Snooped request that some other processor has requested a read exclusive (write) to a cache block. The requesting processor does not have the block yet.
- BusUpgr: Snooped request that some other processor has requested a write to a cache block that it already has.
- Flush: Snooped request that indicates that entire cache block has been placed on the bus for cache to cache transfer
- FlushOpt: Snooped request that indicates that entire cache block has been placed on the bus for cache to cache transfer. Itâ€™s called FlushOpt because  it offers performance enhancement and it is not really a correctness requirement.

**NOTE:** For a BusRd transaction, if a copy is found by other snoopers, they assert the COPIES-EXIST line (C) else the line is low (!C).

<div class="text-center">
  {% include figure.html path="assets/img/proc_init.jpg" class="img-fluid rounded w-75" 
  caption="Processor Side" %}
  {% include figure.html path="assets/img/bus_init.jpg" class="img-fluid rounded w-75" 
  caption="Bus Side" %}
</div>

For the processor side, the state diagram uses the notation Processor_request/Resulting_bus_transaction and for the bus side it is snooped_transaction/resulting_action.

The advantages of this protocol??? Well it allows dirty sharing and reduces traffic due to writebacks. It saves power when compared to MESI protocol. How? Well in case of MESI, the FlushOpt is generated by multiple caches in â€˜Sâ€™ state, but only one is selected for cache-to-cache transfer. So, power is spent in reading the cache, trying to obtain bus access and then cancelling it when a cache senses that someone else has supplied the block earlier. This is avoided because FlushOpt will only be sent by the cache block in â€˜Smâ€™ state. Hence, read after read requests will also get cache-to-cache transfers. The resulting off-chip bandwidth usage was the least for the same benchmark using MOESISm protocol.Yayyy!!!

The only drawback which I can notice for this protocol is that, for MESIF the â€˜Fâ€™ state migrates to a newer copy as [mentioned here](http://www.realworldtech.com/common-system-interface/5/) and the newer copy has lesser chances of getting evicted (temporal locality). However, in the protocol I have suggested, the migration of â€˜Smâ€™ state is not possible because with the current hardware we only have one Copies exists line. Now, if the newer copy has to go into â€˜Smâ€™ state, then the older copy may either be in â€˜Eâ€™ state OR in â€˜Oâ€™ state OR in â€˜Smâ€™ state. Here, all these intial states should transition into â€˜Sâ€™ state but if the â€˜Oâ€™ state moves into â€˜Sâ€™ state then what happens to the writeback??? Well, I guess if we change the protocol so that the â€˜Oâ€™ state performs a writeback when it moves into â€˜Sâ€™ state, then this can be achieved. I just thought of this last part now ðŸ˜€ I guess blogging really helps!!!
